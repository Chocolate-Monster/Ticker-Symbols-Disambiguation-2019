{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from time import sleep\n",
    "\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "import requests\n",
    "from twitterscraper import query_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read ticker list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tickers.txt', 'r') as f:\n",
    "    ticker_list = [t.strip() for t in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive examples (the word IS a ticker) are retrieved from https://stocktwits.com/ .\n",
    "\n",
    "Stocktwits is The Largest Social Network For Investors And Traders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnknownStocktwitsError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Stocktwits:\n",
    "    \"\"\"This class downloads the twits to ./stocktwits_{name} directory so, \n",
    "        that the dowloading could be aborted and continued\n",
    "        To do so this class has some special features: \n",
    "            * log file: contains ticker name and the number of dowloaded twits\n",
    "            * ticker list: updates by popping out the ticker name, which is complete\n",
    "    \"\"\"\n",
    "    def __init__(self, count, ticker_list, name):\n",
    "        \"\"\"initial parameters:\n",
    "             * count - how many twits for one ticket are needed, \n",
    "             * ticker_list - tickers to download, \n",
    "             * name - the name of directory for saving tickers\n",
    "        \"\"\"\n",
    "        self.total_count = count\n",
    "        self.ticker_list = ticker_list.copy()\n",
    "        self.path = './stocktwits_{}/'.format(name)\n",
    "        if not os.path.exists(self.path):\n",
    "            os.mkdir(self.path)\n",
    "        if not os.path.exists(self.path + 'log.json'):\n",
    "            with open(self.path + 'log.json', 'w') as f:\n",
    "                json.dump({}, f)\n",
    "        \n",
    "    def where_to_start(self):\n",
    "        \"\"\"gets the start parameters. \n",
    "           input: None\n",
    "           output: \n",
    "                * ticker - ticker name\n",
    "                * scrolling_arg - parameter for url adress to continue download\n",
    "                * count - number of twits left to get\n",
    "        \"\"\"\n",
    "        with open(self.path + 'log.json', 'r') as f:\n",
    "            log = json.load(f)\n",
    "        ticker = self.ticker_list[0]\n",
    "        \n",
    "        if ticker not in log:\n",
    "            scrolling_arg = None\n",
    "            count = self.total_count\n",
    "        elif log[ticker]['count'] >= self.total_count:\n",
    "            self.ticker_list.remove(ticker)\n",
    "            \n",
    "            return self.where_to_start()\n",
    "        else:\n",
    "            scrolling_arg = log[ticker]['scrolling_arg']\n",
    "            count = self.total_count - log[ticker]['count']\n",
    "            \n",
    "        return ticker, scrolling_arg, count\n",
    "    \n",
    "    def download_data(self):\n",
    "        \"\"\"downloads twits \n",
    "            input: None\n",
    "            output: \n",
    "                * ticker - ticker name\n",
    "                * texts - twits as a list of dicts (json format)\n",
    "                * scrolling_arg - parameter for url adress used the last\n",
    "        \"\"\"\n",
    "        \n",
    "        ticker, scrolling_arg, count = self.where_to_start()\n",
    "        # Stocktwits.com returns twits in batches sized 30\n",
    "        # n = number of requsts needed\n",
    "        n = count // 30 + 1\n",
    "        texts = []\n",
    "        \n",
    "        if scrolling_arg:\n",
    "            r = requests.get(\n",
    "                'https://api.stocktwits.com/api/2/streams/symbol/{}.json?'.format(ticker),\n",
    "                params={\n",
    "                    'filter': 'all',\n",
    "                    'max': scrolling_arg\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            r = requests.get(\n",
    "                'https://api.stocktwits.com/api/2/streams/symbol/{}.json?'.format(ticker),\n",
    "                params={\n",
    "                    'filter': 'all'\n",
    "                }\n",
    "            )\n",
    "                \n",
    "        for i in tqdm.tqdm(range(n)):\n",
    "            \n",
    "            content = json.loads(r.text)\n",
    "            status = content['response']['status']\n",
    "            \n",
    "            if status != 200:               \n",
    "                print('ticker', ticker)\n",
    "                print('status: ', content['response']['status'])\n",
    "                print('error: ', content['errors'][0]['message'])\n",
    "                \n",
    "                # if no twits left or there are no twits with demanded ticker\n",
    "                if status == 404:\n",
    "                    self.ticker_list.remove(ticker) \n",
    "                if texts: \n",
    "                    return ticker, texts, scrolling_arg\n",
    "                else:\n",
    "                    # here mostly goes \"requests limit exceeded\" error\n",
    "                    raise UnknownStocktwitsError\n",
    "\n",
    "            messages = content['messages']\n",
    "            \n",
    "            texts.extend(messages)\n",
    "            \n",
    "            #scrolling parameters\n",
    "            cursor_more = content['cursor']['more']\n",
    "            scrolling_arg = content['cursor']['max']\n",
    "            \n",
    "            if cursor_more:\n",
    "                r = requests.get(\n",
    "                    'https://api.stocktwits.com/api/2/streams/symbol/{}.json?'.format(ticker),\n",
    "                    params={\n",
    "                        'filter': 'all',\n",
    "                        'max': scrolling_arg\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                self.ticker_list.remove(ticker)\n",
    "                return ticker, texts, scrolling_arg\n",
    "\n",
    "        return ticker, texts, scrolling_arg    \n",
    "      \n",
    "    def save_results(self, ticker, texts, scrolling_arg):\n",
    "        \"\"\"save twits as a json file to the `self.path` directory and write log to log.json\n",
    "            input: ticker, texts, scrolling_arg (see `self.download_data`)\n",
    "            output: None\n",
    "        \"\"\"\n",
    "        \n",
    "        full_path = '{}{}_{}_{}.json'.format(\n",
    "            self.path,\n",
    "            ticker,\n",
    "            scrolling_arg,\n",
    "            datetime.datetime.now()\n",
    "        )\n",
    "         \n",
    "        with open(full_path, 'w') as f:\n",
    "            json.dump(texts, f)\n",
    "\n",
    "        with open(self.path + 'log.json', 'r') as f:\n",
    "            log = json.load(f)\n",
    "\n",
    "        if ticker in log:\n",
    "            log[ticker]['scrolling_arg'] = scrolling_arg\n",
    "            log[ticker]['count'] += len(texts)\n",
    "            if log[ticker]['count'] >= self.total_count:\n",
    "                self.ticker_list.remove(ticker)\n",
    "        else:\n",
    "            log[ticker] = {\n",
    "                'scrolling_arg': scrolling_arg,\n",
    "                'count': len(texts)\n",
    "            }\n",
    "\n",
    "        with open(self.path + 'log.json', 'w') as f:\n",
    "            json.dump(log, f)\n",
    "            \n",
    "    def try_to_download(self):\n",
    "        \"\"\"This function downloads all needed data.\n",
    "        Stocktwits.com allows only 200 requests per hour, \n",
    "        that's why after failure the program goes to sleep for 15 minutes\"\"\"\n",
    "        while len(self.ticker_list) > 0:\n",
    "            try:\n",
    "                ticker, texts, scrolling_arg = self.download_data()\n",
    "                print(ticker, 'saved')\n",
    "                self.save_results(ticker, texts, scrolling_arg)\n",
    "            except UnknownStocktwitsError:\n",
    "                print('sleeping at ', datetime.datetime.now().time())\n",
    "                sleep(15 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "stktwts = Stocktwits(3000, ticker_list, 'hope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stktwts.try_to_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative examples (the word is NOT a ticker) are retrieved from https://twitter.com/ using twitterscraper https://github.com/taspinar/twitterscraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets about 3000 (parameter 'limit') tweets per ticker, starting from 01/01/2018 (parameter 'begindate') \n",
    "for query_word in tqdm.tqdm(ticker_list, total=len(ticker_list)):\n",
    "    tweets = [tweet.text.replace('\\n', ' ') for tweet in query_tweets(\n",
    "                query_word,  \n",
    "                limit=3000, \n",
    "                begindate=datetime.date(2018, 1, 1),\n",
    "                lang='en'\n",
    "                )\n",
    "             ]\n",
    "    print(query_word, len(tweets))\n",
    "\n",
    "    with open('./twitter/{}_{}'.format(query_word, datetime.datetime.now()), 'w') as f:\n",
    "        f.write('\\n'.join(tweets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
